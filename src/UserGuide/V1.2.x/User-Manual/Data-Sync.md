<!--

    Licensed to the Apache Software Foundation (ASF) under one
    or more contributor license agreements.  See the NOTICE file
    distributed with this work for additional information
    regarding copyright ownership.  The ASF licenses this file
    to you under the Apache License, Version 2.0 (the
    "License"); you may not use this file except in compliance
    with the License.  You may obtain a copy of the License at
    
        http://www.apache.org/licenses/LICENSE-2.0
    
    Unless required by applicable law or agreed to in writing,
    software distributed under the License is distributed on an
    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
    KIND, either express or implied.  See the License for the
    specific language governing permissions and limitations
    under the License.

-->

# IoTDB Data Sync
**The IoTDB data sync transfers data from IoTDB to another data platform, and <font color=RED>a data sync task is called a Pipe</font>.**

**A Pipe consists of three subtasks (plugins): **

- Extract
- Process
- Connect

**Pipe allows users to customize the processing logic of these three subtasks, just like handling data using UDF (User-Defined Functions)**. Within a Pipe, the aforementioned subtasks are executed and implemented by three types of plugins. Data flows through these three plugins sequentially: Pipe Extractor is used to extract data, Pipe Processor is used to process data, and Pipe Connector is used to send data to an external system.

**The model of a Pipe task is as follows: **

![Task model diagram](https://alioss.timecho.com/docs/img/%E6%B5%81%E5%A4%84%E7%90%86%E5%BC%95%E6%93%8E.jpeg)

It describes a data synchronization task, which essentially describes the attributes of the Pipe Extractor, Pipe Processor, and Pipe Connector plugins. Users can declaratively configure the specific attributes of the three subtasks through SQL statements. By combining different attributes, flexible data ETL (Extract, Transform, Load) capabilities can be achieved.

By utilizing the data synchronization functionality, a complete data pipeline can be built to fulfill various requirements such as edge-to-cloud synchronization, remote disaster recovery, and read-write workload distribution across multiple databases.

## Quick Start

**ğŸ¯ Goal: Achieve full data synchronisation of IoTDB A -> IoTDB B**

- Start two IoTDBs,Aï¼ˆdatanode -> 127.0.0.1:6667ï¼‰ Bï¼ˆdatanode -> 127.0.0.1:6668ï¼‰
- create a Pipe from A -> B, and execute on A

  ```sql
  create pipe a2b
  with connector (
    'connector'='iotdb-thrift-connector',
    'connector.ip'='127.0.0.1',
    'connector.port'='6668'
  )
  ```
- start a Pipe from A -> B, and execute on A

  ```sql
  start pipe a2b
  ```
- Write data to A

  ```sql
  INSERT INTO root.db.d(time, m) values (1, 1)
  ```
- Checking data synchronised from A at B
  ```sql
  SELECT ** FROM root
  ```

> â—ï¸**Note: The current IoTDB -> IoTDB implementation of data synchronisation does not support DDL synchronisation**
>
> That is: ttl, trigger, alias, template, view, create/delete sequence, create/delete storage group, etc. are not supported.
>
> **IoTDB -> IoTDB data synchronisation requires the target IoTDB:**
>
> * Enable automatic metadata creation: manual configuration of encoding and compression of data types to be consistent with the sender is required
> * Do not enable automatic metadata creation: manually create metadata that is consistent with the source

## Synchronization task management

### Create a synchronization task

A data synchronisation task can be created using the `CREATE PIPE` statement, a sample SQL statement is shown below:

```sql
CREATE PIPE <PipeId> -- PipeId is the name that uniquely identifies the synchronisation task
WITH EXTRACTOR (
  -- Default IoTDB Data Extraction Plugin
  'extractor'                    = 'iotdb-extractor',
  -- Path prefix, only data that can match the path prefix will be extracted for subsequent processing and delivery
  'extractor.pattern'            = 'root.timecho',
  -- Whether to extract historical data
  'extractor.history.enable'     = 'true',
  -- Describes the time range of the historical data being extracted, indicating the earliest possible time
  'extractor.history.start-time' = '2011.12.03T10:15:30+01:00',
  -- Describes the time range of the extracted historical data, indicating the latest time
  'extractor.history.end-time'   = '2022.12.03T10:15:30+01:00',
  -- Whether to extract real-time data
  'extractor.realtime.enable'    = 'true',
)
WITH PROCESSOR (
  -- Default data processing plugin, means no processing
  'processor'                    = 'do-nothing-processor',
)
WITH CONNECTOR (
  -- IoTDB data sending plugin with target IoTDB
  'connector'                    = 'iotdb-thrift-connector',
  -- Data service for one of the DataNode nodes on the target IoTDB ip
  'connector.ip'                 = '127.0.0.1',
  -- Data service port of one of the DataNode nodes of the target IoTDB
  'connector.port'               = '6667',
)
```

**To create a synchronisation task it is necessary to configure the PipeId and the parameters of the three plugin sections:**


| é…ç½®é¡¹    | è¯´æ˜                                              | æ˜¯å¦å¿…å¡«                    | é»˜è®¤å®ç°             | é»˜è®¤å®ç°è¯´æ˜                                           | æ˜¯å¦å…è®¸è‡ªå®šä¹‰å®ç°        |
| --------- | ------------------------------------------------- | --------------------------- | -------------------- | ------------------------------------------------------ | ------------------------- |
| PipeId    | å…¨å±€å”¯ä¸€æ ‡å®šä¸€ä¸ªåŒæ­¥ä»»åŠ¡çš„åç§°                    | <font color=red>å¿…å¡«</font> | -                    | -                                                      | -                         |
| extractor | Pipe Extractor æ’ä»¶ï¼Œè´Ÿè´£åœ¨æ•°æ®åº“åº•å±‚æŠ½å–åŒæ­¥æ•°æ® | é€‰å¡«                        | iotdb-extractor      | å°†æ•°æ®åº“çš„å…¨é‡å†å²æ•°æ®å’Œåç»­åˆ°è¾¾çš„å®æ—¶æ•°æ®æ¥å…¥åŒæ­¥ä»»åŠ¡ | å¦                        |
| processor | Pipe Processor æ’ä»¶ï¼Œè´Ÿè´£å¤„ç†æ•°æ®                 | é€‰å¡«                        | do-nothing-processor | å¯¹ä¼ å…¥çš„æ•°æ®ä¸åšä»»ä½•å¤„ç†                               | <font color=red>æ˜¯</font> |
| connector | Pipe Connector æ’ä»¶ï¼Œè´Ÿè´£å‘é€æ•°æ®                 | <font color=red>å¿…å¡«</font> | -                    | -                                                      | <font color=red>æ˜¯</font> |

In the example, the iotdb-extractor, do-nothing-processor, and iotdb-thrift-connector plug-ins are used to build the data synchronisation task. iotdb has other built-in data synchronisation plug-ins, **see the section "System pre-built data synchronisation plug-ins" **. See the "System Preconfigured Data Synchronisation Plugins" section**.

**An example of a minimalist CREATE PIPE statement is as follows:**

```sql
CREATE PIPE <PipeId> -- PipeId æ˜¯èƒ½å¤Ÿå”¯ä¸€æ ‡å®šä»»åŠ¡ä»»åŠ¡çš„åå­—
WITH CONNECTOR (
  -- IoTDB æ•°æ®å‘é€æ’ä»¶ï¼Œç›®æ ‡ç«¯ä¸º IoTDB
  'connector'      = 'iotdb-thrift-connector',
  -- ç›®æ ‡ç«¯ IoTDB å…¶ä¸­ä¸€ä¸ª DataNode èŠ‚ç‚¹çš„æ•°æ®æœåŠ¡ ip
  'connector.ip'   = '127.0.0.1',
  -- ç›®æ ‡ç«¯ IoTDB å…¶ä¸­ä¸€ä¸ª DataNode èŠ‚ç‚¹çš„æ•°æ®æœåŠ¡ port
  'connector.port' = '6667',
)
```

The expressed semantics are: synchronise the full amount of historical data and subsequent arrivals of real-time data from this database instance to the IoTDB instance with target 127.0.0.1:6667.

**æ³¨æ„ï¼š**

- EXTRACTOR å’Œ PROCESSOR ä¸ºé€‰å¡«é…ç½®ï¼Œè‹¥ä¸å¡«å†™é…ç½®å‚æ•°ï¼Œç³»ç»Ÿåˆ™ä¼šé‡‡ç”¨ç›¸åº”çš„é»˜è®¤å®ç°
- CONNECTOR ä¸ºå¿…å¡«é…ç½®ï¼Œéœ€è¦åœ¨ CREATE PIPE è¯­å¥ä¸­å£°æ˜å¼é…ç½®
- CONNECTOR å…·å¤‡è‡ªå¤ç”¨èƒ½åŠ›ã€‚å¯¹äºä¸åŒçš„ä»»åŠ¡ï¼Œå¦‚æœä»–ä»¬çš„ CONNECTOR å…·å¤‡å®Œå…¨ç›¸åŒ KV å±æ€§çš„ï¼ˆæ‰€æœ‰å±æ€§çš„ key å¯¹åº”çš„ value éƒ½ç›¸åŒï¼‰ï¼Œ**é‚£ä¹ˆç³»ç»Ÿæœ€ç»ˆåªä¼šåˆ›å»ºä¸€ä¸ª CONNECTOR å®ä¾‹**ï¼Œä»¥å®ç°å¯¹è¿æ¥èµ„æºçš„å¤ç”¨ã€‚

  - ä¾‹å¦‚ï¼Œæœ‰ä¸‹é¢ pipe1, pipe2 ä¸¤ä¸ªä»»åŠ¡çš„å£°æ˜ï¼š

  ```sql
  CREATE PIPE pipe1
  WITH CONNECTOR (
    'connector' = 'iotdb-thrift-connector',
    'connector.thrift.host' = 'localhost',
    'connector.thrift.port' = '9999',
  )

  CREATE PIPE pipe2
  WITH CONNECTOR (
    'connector' = 'iotdb-thrift-connector',
    'connector.thrift.port' = '9999',
    'connector.thrift.host' = 'localhost',
  )
  ```

  - å› ä¸ºå®ƒä»¬å¯¹ CONNECTOR çš„å£°æ˜å®Œå…¨ç›¸åŒï¼ˆ**å³ä½¿æŸäº›å±æ€§å£°æ˜æ—¶çš„é¡ºåºä¸åŒ**ï¼‰ï¼Œæ‰€ä»¥æ¡†æ¶ä¼šè‡ªåŠ¨å¯¹å®ƒä»¬å£°æ˜çš„ CONNECTOR è¿›è¡Œå¤ç”¨ï¼Œæœ€ç»ˆ pipe1, pipe2 çš„CONNECTOR å°†ä¼šæ˜¯åŒä¸€ä¸ªå®ä¾‹ã€‚
- è¯·ä¸è¦æ„å»ºå‡ºåŒ…å«æ•°æ®å¾ªç¯åŒæ­¥çš„åº”ç”¨åœºæ™¯ï¼ˆä¼šå¯¼è‡´æ— é™å¾ªç¯ï¼‰ï¼š

  - IoTDB A -> IoTDB B -> IoTDB A
  - IoTDB A -> IoTDB A

### å¯åŠ¨ä»»åŠ¡

CREATE PIPE è¯­å¥æˆåŠŸæ‰§è¡Œåï¼Œä»»åŠ¡ç›¸å…³å®ä¾‹ä¼šè¢«åˆ›å»ºï¼Œä½†æ•´ä¸ªä»»åŠ¡çš„è¿è¡ŒçŠ¶æ€ä¼šè¢«ç½®ä¸º STOPPEDï¼Œå³ä»»åŠ¡ä¸ä¼šç«‹åˆ»å¤„ç†æ•°æ®ã€‚

å¯ä»¥ä½¿ç”¨ START PIPE è¯­å¥ä½¿ä»»åŠ¡å¼€å§‹å¤„ç†æ•°æ®ï¼š

```sql
START PIPE <PipeId>
```

### åœæ­¢ä»»åŠ¡

ä½¿ç”¨ STOP PIPE è¯­å¥ä½¿ä»»åŠ¡åœæ­¢å¤„ç†æ•°æ®ï¼š

```sql
STOP PIPE <PipeId>
```

### åˆ é™¤ä»»åŠ¡

ä½¿ç”¨ DROP PIPE è¯­å¥ä½¿ä»»åŠ¡åœæ­¢å¤„ç†æ•°æ®ï¼ˆå½“ä»»åŠ¡çŠ¶æ€ä¸º RUNNING æ—¶ï¼‰ï¼Œç„¶ååˆ é™¤æ•´ä¸ªä»»åŠ¡åŒæ­¥ä»»åŠ¡ï¼š

```sql
DROP PIPE <PipeId>
```

ç”¨æˆ·åœ¨åˆ é™¤ä»»åŠ¡å‰ï¼Œä¸éœ€è¦æ‰§è¡Œ STOP æ“ä½œã€‚

### å±•ç¤ºä»»åŠ¡

ä½¿ç”¨ SHOW PIPES è¯­å¥æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡ï¼š

```sql
SHOW PIPES
```

æŸ¥è¯¢ç»“æœå¦‚ä¸‹ï¼š

```sql
+-----------+-----------------------+-------+-------------+-------------+-------------+----------------+
|         ID|          CreationTime |  State|PipeExtractor|PipeProcessor|PipeConnector|ExceptionMessage|
+-----------+-----------------------+-------+-------------+-------------+-------------+----------------+
|iotdb-kafka|2022-03-30T20:58:30.689|RUNNING|          ...|          ...|          ...|            None|
+-----------+-----------------------+-------+-------------+-------------+-------------+----------------+
|iotdb-iotdb|2022-03-31T12:55:28.129|STOPPED|          ...|          ...|          ...| TException: ...|
+-----------+-----------------------+-------+-------------+-------------+-------------+----------------+
```

å¯ä»¥ä½¿ç”¨ `<PipeId>` æŒ‡å®šæƒ³çœ‹çš„æŸä¸ªåŒæ­¥ä»»åŠ¡çŠ¶æ€ï¼š

```sql
SHOW PIPE <PipeId>
```

æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡ where å­å¥ï¼Œåˆ¤æ–­æŸä¸ª \<PipeId\> ä½¿ç”¨çš„ Pipe Connector è¢«å¤ç”¨çš„æƒ…å†µã€‚

```sql
SHOW PIPES
WHERE CONNECTOR USED BY <PipeId>
```

### ä»»åŠ¡è¿è¡ŒçŠ¶æ€è¿ç§»

ä¸€ä¸ªæ•°æ®åŒæ­¥ pipe åœ¨å…¶è¢«ç®¡ç†çš„ç”Ÿå‘½å‘¨æœŸä¸­ä¼šç»è¿‡å¤šç§çŠ¶æ€ï¼š

- **STOPPEDï¼š** pipe å¤„äºåœæ­¢è¿è¡ŒçŠ¶æ€ã€‚å½“ç®¡é“å¤„äºè¯¥çŠ¶æ€æ—¶ï¼Œæœ‰å¦‚ä¸‹å‡ ç§å¯èƒ½ï¼š
  - å½“ä¸€ä¸ª pipe è¢«æˆåŠŸåˆ›å»ºä¹‹åï¼Œå…¶åˆå§‹çŠ¶æ€ä¸ºæš‚åœçŠ¶æ€
  - ç”¨æˆ·æ‰‹åŠ¨å°†ä¸€ä¸ªå¤„äºæ­£å¸¸è¿è¡ŒçŠ¶æ€çš„ pipe æš‚åœï¼Œå…¶çŠ¶æ€ä¼šè¢«åŠ¨ä» RUNNING å˜ä¸º STOPPED
  - å½“ä¸€ä¸ª pipe è¿è¡Œè¿‡ç¨‹ä¸­å‡ºç°æ— æ³•æ¢å¤çš„é”™è¯¯æ—¶ï¼Œå…¶çŠ¶æ€ä¼šè‡ªåŠ¨ä» RUNNING å˜ä¸º STOPPED
- **RUNNINGï¼š** pipe æ­£åœ¨æ­£å¸¸å·¥ä½œ
- **DROPPEDï¼š** pipe ä»»åŠ¡è¢«æ°¸ä¹…åˆ é™¤

ä¸‹å›¾è¡¨æ˜äº†æ‰€æœ‰çŠ¶æ€ä»¥åŠçŠ¶æ€çš„è¿ç§»ï¼š

![çŠ¶æ€è¿ç§»å›¾](https://alioss.timecho.com/docs/img/%E7%8A%B6%E6%80%81%E8%BF%81%E7%A7%BB%E5%9B%BE.png)

## ç³»ç»Ÿé¢„ç½®æ•°æ®åŒæ­¥æ’ä»¶

### æŸ¥çœ‹é¢„ç½®æ’ä»¶

ç”¨æˆ·å¯ä»¥æŒ‰éœ€æŸ¥çœ‹ç³»ç»Ÿä¸­çš„æ’ä»¶ã€‚æŸ¥çœ‹æ’ä»¶çš„è¯­å¥å¦‚å›¾æ‰€ç¤ºã€‚

```sql
SHOW PIPEPLUGINS
```

### é¢„ç½® extractor æ’ä»¶

#### iotdb-extractor

ä½œç”¨ï¼šæŠ½å– IoTDB å†…éƒ¨çš„å†å²æˆ–å®æ—¶æ•°æ®è¿›å…¥ pipeã€‚


| key                                | value                                            | value range                         | required or optional with default |
| ---------------------------------- | ------------------------------------------------ | -------------------------------------- | --------------------------------- |
| extractor                          | iotdb-extractor                                  | String: iotdb-extractor                | required                          |
| extractor.pattern                  | ç”¨äºç­›é€‰æ—¶é—´åºåˆ—çš„è·¯å¾„å‰ç¼€                       | String: ä»»æ„çš„æ—¶é—´åºåˆ—å‰ç¼€             | optional: root                    |
| extractor.history.enable           | æ˜¯å¦åŒæ­¥å†å²æ•°æ®                                 | Boolean: true, false                   | optional: true                    |
| extractor.history.start-time       | åŒæ­¥å†å²æ•°æ®çš„å¼€å§‹ event timeï¼ŒåŒ…å« start-time   | Long: [Long.MIN_VALUE, Long.MAX_VALUE] | optional: Long.MIN_VALUE          |
| extractor.history.end-time         | åŒæ­¥å†å²æ•°æ®çš„ç»“æŸ event timeï¼ŒåŒ…å« end-time     | Long: [Long.MIN_VALUE, Long.MAX_VALUE] | optional: Long.MAX_VALUE          |
| extractor.realtime.enable          | æ˜¯å¦åŒæ­¥å®æ—¶æ•°æ®                                 | Boolean: true, false                   | optional: true                    |

> ğŸš« **extractor.pattern å‚æ•°è¯´æ˜**
>
> * Pattern éœ€ç”¨åå¼•å·ä¿®é¥°ä¸åˆæ³•å­—ç¬¦æˆ–è€…æ˜¯ä¸åˆæ³•è·¯å¾„èŠ‚ç‚¹ï¼Œä¾‹å¦‚å¦‚æœå¸Œæœ›ç­›é€‰ root.\`a@b\` æˆ–è€… root.\`123\`ï¼Œåº”è®¾ç½® pattern ä¸º root.\`a@b\` æˆ–è€… root.\`123\`ï¼ˆå…·ä½“å‚è€ƒ [å•åŒå¼•å·å’Œåå¼•å·çš„ä½¿ç”¨æ—¶æœº](https://iotdb.apache.org/zh/Download/#_1-0-ç‰ˆæœ¬ä¸å…¼å®¹çš„è¯­æ³•è¯¦ç»†è¯´æ˜)ï¼‰
> * åœ¨åº•å±‚å®ç°ä¸­ï¼Œå½“æ£€æµ‹åˆ° pattern ä¸º rootï¼ˆé»˜è®¤å€¼ï¼‰æ—¶ï¼ŒåŒæ­¥æ•ˆç‡è¾ƒé«˜ï¼Œå…¶ä»–ä»»æ„æ ¼å¼éƒ½å°†é™ä½æ€§èƒ½
> * è·¯å¾„å‰ç¼€ä¸éœ€è¦èƒ½å¤Ÿæ„æˆå®Œæ•´çš„è·¯å¾„ã€‚ä¾‹å¦‚ï¼Œå½“åˆ›å»ºä¸€ä¸ªåŒ…å«å‚æ•°ä¸º 'extractor.pattern'='root.aligned.1' çš„ pipe æ—¶ï¼š
>
>   * root.aligned.1TS
>   * root.aligned.1TS.\`1\`
>   * root.aligned.100TS
>
>   çš„æ•°æ®ä¼šè¢«åŒæ­¥ï¼›
>
>   * root.aligned.\`1\`
>   * root.aligned.\`123\`
>
>   çš„æ•°æ®ä¸ä¼šè¢«åŒæ­¥ã€‚

> â—ï¸**extractor.history çš„ start-timeï¼Œend-time å‚æ•°è¯´æ˜**
>
> * start-timeï¼Œend-time åº”ä¸º ISO æ ¼å¼ï¼Œä¾‹å¦‚ 2011-12-03T10:15:30 æˆ– 2011-12-03T10:15:30+01:00

> âœ… **ä¸€æ¡æ•°æ®ä»ç”Ÿäº§åˆ°è½åº“ IoTDBï¼ŒåŒ…å«ä¸¤ä¸ªå…³é”®çš„æ—¶é—´æ¦‚å¿µ**
>
> * **event timeï¼š** æ•°æ®å®é™…ç”Ÿäº§æ—¶çš„æ—¶é—´ï¼ˆæˆ–è€…æ•°æ®ç”Ÿäº§ç³»ç»Ÿç»™æ•°æ®èµ‹äºˆçš„ç”Ÿæˆæ—¶é—´ï¼Œæ˜¯æ•°æ®ç‚¹ä¸­çš„æ—¶é—´é¡¹ï¼‰ï¼Œä¹Ÿç§°ä¸ºäº‹ä»¶æ—¶é—´ã€‚
> * **arrival timeï¼š** æ•°æ®åˆ°è¾¾ IoTDB ç³»ç»Ÿå†…çš„æ—¶é—´ã€‚
>
> æˆ‘ä»¬å¸¸è¯´çš„ä¹±åºæ•°æ®ï¼ŒæŒ‡çš„æ˜¯æ•°æ®åˆ°è¾¾æ—¶ï¼Œå…¶ **event time** è¿œè½åäºå½“å‰ç³»ç»Ÿæ—¶é—´ï¼ˆæˆ–è€…å·²ç»è½åº“çš„æœ€å¤§ **event time**ï¼‰çš„æ•°æ®ã€‚å¦ä¸€æ–¹é¢ï¼Œä¸è®ºæ˜¯ä¹±åºæ•°æ®è¿˜æ˜¯é¡ºåºæ•°æ®ï¼Œåªè¦å®ƒä»¬æ˜¯æ–°åˆ°è¾¾ç³»ç»Ÿçš„ï¼Œé‚£å®ƒä»¬çš„ **arrival time** éƒ½æ˜¯ä¼šéšç€æ•°æ®åˆ°è¾¾ IoTDB çš„é¡ºåºé€’å¢çš„ã€‚

> ğŸ’ **iotdb-extractor çš„å·¥ä½œå¯ä»¥æ‹†åˆ†æˆä¸¤ä¸ªé˜¶æ®µ**
>
> 1. å†å²æ•°æ®æŠ½å–ï¼šæ‰€æœ‰ **arrival time** < åˆ›å»º pipe æ—¶**å½“å‰ç³»ç»Ÿæ—¶é—´**çš„æ•°æ®ç§°ä¸ºå†å²æ•°æ®
> 2. å®æ—¶æ•°æ®æŠ½å–ï¼šæ‰€æœ‰ **arrival time** >= åˆ›å»º pipe æ—¶**å½“å‰ç³»ç»Ÿæ—¶é—´**çš„æ•°æ®ç§°ä¸ºå®æ—¶æ•°æ®
>
> å†å²æ•°æ®ä¼ è¾“é˜¶æ®µå’Œå®æ—¶æ•°æ®ä¼ è¾“é˜¶æ®µï¼Œ**ä¸¤é˜¶æ®µä¸²è¡Œæ‰§è¡Œï¼Œåªæœ‰å½“å†å²æ•°æ®ä¼ è¾“é˜¶æ®µå®Œæˆåï¼Œæ‰æ‰§è¡Œå®æ—¶æ•°æ®ä¼ è¾“é˜¶æ®µã€‚**
>
> ç”¨æˆ·å¯ä»¥æŒ‡å®š iotdb-extractor è¿›è¡Œï¼š
>
> * å†å²æ•°æ®æŠ½å–ï¼ˆ`'extractor.history.enable' = 'true'`, `'extractor.realtime.enable' = 'false'` ï¼‰
> * å®æ—¶æ•°æ®æŠ½å–ï¼ˆ`'extractor.history.enable' = 'false'`, `'extractor.realtime.enable' = 'true'` ï¼‰
> * å…¨é‡æ•°æ®æŠ½å–ï¼ˆ`'extractor.history.enable' = 'true'`, `'extractor.realtime.enable' = 'true'` ï¼‰
> * ç¦æ­¢åŒæ—¶è®¾ç½® `extractor.history.enable` å’Œ `extractor.realtime.enable` ä¸º `false`

### pre-processor plugin

#### do-nothing-processor

Function: Do not do anything with the events passed in by the extractor.


| key       | value                | value range               | required or optional with default |
| --------- | -------------------- | ---------------------------- | --------------------------------- |
| processor | do-nothing-processor | String: do-nothing-processor | required                          |

### pre-connector plugin

#### iotdb-thrift-sync-connector(alias:iotdb-thrift-connector)

Function: Primarily used for data transfer between IoTDB instances (v1.2.0+). Data is transmitted using the Thrift RPC framework and a single-threaded blocking IO model. It guarantees that the receiving end applies the data in the same order as the sending end receives the write requests.

Limitation: Both the source and target IoTDB versions need to be v1.2.0+.


| key                               | value                                                                       | value range                                                               | required or optional with default                     |
| --------------------------------- | --------------------------------------------------------------------------- | ---------------------------------------------------------------------------- | ----------------------------------------------------- |
| connector                         | iotdb-thrift-connector æˆ– iotdb-thrift-sync-connector                       | String: iotdb-thrift-connector æˆ– iotdb-thrift-sync-connector                | required                                              |
| connector.ip                      | ç›®æ ‡ç«¯ IoTDB å…¶ä¸­ä¸€ä¸ª DataNode èŠ‚ç‚¹çš„æ•°æ®æœåŠ¡ ip                            | String                                                                       | optional: ä¸ connector.node-urls ä»»é€‰å…¶ä¸€å¡«å†™         |
| connector.port                    | ç›®æ ‡ç«¯ IoTDB å…¶ä¸­ä¸€ä¸ª DataNode èŠ‚ç‚¹çš„æ•°æ®æœåŠ¡ port                          | Integer                                                                      | optional: ä¸ connector.node-urls ä»»é€‰å…¶ä¸€å¡«å†™         |
| connector.node-urls               | ç›®æ ‡ç«¯ IoTDB ä»»æ„å¤šä¸ª DataNode èŠ‚ç‚¹çš„æ•°æ®æœåŠ¡ç«¯å£çš„ url                     | Stringã€‚ä¾‹ï¼š'127.0.0.1:6667,127.0.0.1:6668,127.0.0.1:6669', '127.0.0.1:6667' | optional: ä¸ connector.ip:connector.port ä»»é€‰å…¶ä¸€å¡«å†™ |

> ğŸ“Œ Please ensure that the receiving end has already created all the time series present in the sending end or has enabled automatic metadata creation. Otherwise, it may result in the failure of the pipe operation.

#### iotdb-thrift-async-connector

Function: Primarily used for data transfer between IoTDB instances (v1.2.0+).
Data is transmitted using the Thrift RPC framework, employing a multi-threaded async non-blocking IO model, resulting in high transfer performance. It is particularly suitable for distributed scenarios on the target end.
It does not guarantee that the receiving end applies the data in the same order as the sending end receives the write requests, but it guarantees data integrity (at-least-once).

Limitation: Both the source and target IoTDB versions need to be v1.2.0+.


| key                               | value                                                                       | value range                                                               | required or optional with default                     |
| --------------------------------- | --------------------------------------------------------------------------- | ---------------------------------------------------------------------------- | ----------------------------------------------------- |
| connector                         | iotdb-thrift-async-connector                                                | String: iotdb-thrift-async-connector                                         | required                                              |
| connector.ip                      | ç›®æ ‡ç«¯ IoTDB å…¶ä¸­ä¸€ä¸ª DataNode èŠ‚ç‚¹çš„æ•°æ®æœåŠ¡ ip                            | String                                                                       | optional: ä¸ connector.node-urls ä»»é€‰å…¶ä¸€å¡«å†™         |
| connector.port                    | ç›®æ ‡ç«¯ IoTDB å…¶ä¸­ä¸€ä¸ª DataNode èŠ‚ç‚¹çš„æ•°æ®æœåŠ¡ port                          | Integer                                                                      | optional: ä¸ connector.node-urls ä»»é€‰å…¶ä¸€å¡«å†™         |
| connector.node-urls               | ç›®æ ‡ç«¯ IoTDB ä»»æ„å¤šä¸ª DataNode èŠ‚ç‚¹çš„æ•°æ®æœåŠ¡ç«¯å£çš„ url                     | Stringã€‚ä¾‹ï¼š'127.0.0.1:6667,127.0.0.1:6668,127.0.0.1:6669', '127.0.0.1:6667' | optional: ä¸ connector.ip:connector.port ä»»é€‰å…¶ä¸€å¡«å†™ |

> ğŸ“Œ Please ensure that the receiving end has already created all the time series present in the sending end or has enabled automatic metadata creation. Otherwise, it may result in the failure of the pipe operation.

#### iotdb-legacy-pipe-connector

Function: Mainly used to transfer data from IoTDB (v1.2.0+) to lower versions of IoTDB, using the data synchronization (Sync) protocol before version v1.2.0.
Data is transmitted using the Thrift RPC framework. It employs a single-threaded sync blocking IO model, resulting in weak transfer performance.

Limitation: The source IoTDB version needs to be v1.2.0+. The target IoTDB version can be either v1.2.0+, v1.1.x (lower versions of IoTDB are theoretically supported but untested).

Note: In theory, any version prior to v1.2.0 of IoTDB can serve as the data synchronization (Sync) receiver for v1.2.0+.


| key                | value                                                                 | value range                      | required or optional with default |
| ------------------ | --------------------------------------------------------------------- | ----------------------------------- | --------------------------------- |
| connector          | iotdb-legacy-pipe-connector                                           | String: iotdb-legacy-pipe-connector | required                          |
| connector.ip       | ç›®æ ‡ç«¯ IoTDB å…¶ä¸­ä¸€ä¸ª DataNode èŠ‚ç‚¹çš„æ•°æ®æœåŠ¡ ip                      | String                              | required                          |
| connector.port     | ç›®æ ‡ç«¯ IoTDB å…¶ä¸­ä¸€ä¸ª DataNode èŠ‚ç‚¹çš„æ•°æ®æœåŠ¡ port                    | Integer                             | required                          |
| connector.user     | ç›®æ ‡ç«¯ IoTDB çš„ç”¨æˆ·åï¼Œæ³¨æ„è¯¥ç”¨æˆ·éœ€è¦æ”¯æŒæ•°æ®å†™å…¥ã€TsFile Load çš„æƒé™ | String                              | optional: root                    |
| connector.password | ç›®æ ‡ç«¯ IoTDB çš„å¯†ç ï¼Œæ³¨æ„è¯¥ç”¨æˆ·éœ€è¦æ”¯æŒæ•°æ®å†™å…¥ã€TsFile Load çš„æƒé™   | String                              | optional: root                    |
| connector.version  | ç›®æ ‡ç«¯ IoTDB çš„ç‰ˆæœ¬ï¼Œç”¨äºä¼ªè£…è‡ªèº«å®é™…ç‰ˆæœ¬ï¼Œç»•è¿‡ç›®æ ‡ç«¯çš„ç‰ˆæœ¬ä¸€è‡´æ€§æ£€æŸ¥ | String                              | optional: 1.1                     |

> ğŸ“Œ Make sure that the receiver has created all the time series on the sender side, or that automatic metadata creation is turned on, otherwise the pipe run will fail.

#### do-nothing-connector

Function: Does not do anything with the events passed in by the processor.


| key       | value                | value range               | required or optional with default |
| --------- | -------------------- | ---------------------------- | --------------------------------- |
| connector | do-nothing-connector | String: do-nothing-connector | required                          |

## Authority Management

| Authority Name    | Description                 |
| ----------- | -------------------- |
| CREATE_PIPE | Register task,path-independent |
| START_PIPE  | Start task,path-independent |
| STOP_PIPE   | Stop task,path-independent |
| DROP_PIPE   | Uninstall task,path-independent |
| SHOW_PIPES  | Query task,path-independent |

## Configure Parameters

In iotdb-common.properties ï¼š

```Properties
####################
### Pipe Configuration
####################

# Uncomment the following field to configure the pipe lib directory.
# For Windows platform
# If its prefix is a drive specifier followed by "\\", or if its prefix is "\\\\", then the path is
# absolute. Otherwise, it is relative.
# pipe_lib_dir=ext\\pipe
# For Linux platform
# If its prefix is "/", then the path is absolute. Otherwise, it is relative.
# pipe_lib_dir=ext/pipe

# The maximum number of threads that can be used to execute the pipe subtasks in PipeSubtaskExecutor.
# The actual value will be min(pipe_subtask_executor_max_thread_num, max(1, CPU core number / 2)).
# pipe_subtask_executor_max_thread_num=5

# The connection timeout (in milliseconds) for the thrift client.
# pipe_connector_timeout_ms=900000

# The maximum number of selectors that can be used in the async connector.
# pipe_async_connector_selector_number=1

# The core number of clients that can be used in the async connector.
# pipe_async_connector_core_client_number=8

# The maximum number of clients that can be used in the async connector.
# pipe_async_connector_max_client_number=16
```

## Functionality Features

### At least one semantic guarantee **at-least-once**

The data synchronization feature provides an at-least-once delivery semantic when transferring data to external systems. In most scenarios, the synchronization feature guarantees exactly-once delivery, ensuring that all data is synchronized exactly once.

However, in the following scenarios, it is possible for some data to be synchronized multiple times **(due to resumable transmission)**:

- Temporary network failures: If a data transmission request fails, the system will retry sending it until reaching the maximum retry attempts.
- Abnormal implementation of the Pipe plugin logic: If an error is thrown during the plugin's execution, the system will retry sending the data until reaching the maximum retry attempts.
- Data partition switching due to node failures or restarts: After the partition change is completed, the affected data will be retransmitted.
- Cluster unavailability: Once the cluster becomes available again, the affected data will be retransmitted.

### Source End: Data Writing with Pipe Processing and Asynchronous Decoupling of Data Transmission

In the data synchronization feature, data transfer adopts an asynchronous replication mode.

Data synchronization is completely decoupled from the writing operation, eliminating any impact on the critical path of writing. This mechanism allows the framework to maintain the writing speed of a time-series database while ensuring continuous data synchronization.

### Source End: High Availability of Pipe Service in a Highly Available Cluster Deployment

When the sender end IoTDB is deployed in a high availability cluster mode, the data synchronization service will also be highly available. The data synchronization framework monitors the data synchronization progress of each data node and periodically takes lightweight distributed consistent snapshots to preserve the synchronization state.

- In the event of a failure of a data node in the sender cluster, the data synchronization framework can leverage the consistent snapshot and the data stored in replicas to quickly recover and resume synchronization, thus achieving high availability of the data synchronization service.
- In the event of a complete failure and restart of the sender cluster, the data synchronization framework can also use snapshots to recover the synchronization service.
